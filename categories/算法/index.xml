<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>算法 on TomtomYoung Blog</title>
    <link>https://gaoshanwomeng.github.io/categories/%E7%AE%97%E6%B3%95/</link>
    <description>Recent content in 算法 on TomtomYoung Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 31 Mar 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://gaoshanwomeng.github.io/categories/%E7%AE%97%E6%B3%95/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>js 算法2</title>
      <link>https://gaoshanwomeng.github.io/post/js-%E7%AE%97%E6%B3%952/</link>
      <pubDate>Wed, 31 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://gaoshanwomeng.github.io/post/js-%E7%AE%97%E6%B3%952/</guid>
      <description>1. 遍历二叉树 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 var {tree} = require(&amp;#39;../重建二叉树/3.js&amp;#39;) //</description>
    </item>
    
    <item>
      <title>js 算法</title>
      <link>https://gaoshanwomeng.github.io/post/js-%E7%AE%97%E6%B3%95/</link>
      <pubDate>Tue, 30 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://gaoshanwomeng.github.io/post/js-%E7%AE%97%E6%B3%95/</guid>
      <description>1. 快速排序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 const arr = [ 31, 23, 34, 2, 13, 134, 1, 23, 456, 52, 31 ]; function quickSort(arr) { // 1.找基准数， // 比基准数大的放右边（右数组） // 比基准数小的放左边</description>
    </item>
    
    <item>
      <title>偏差与方差</title>
      <link>https://gaoshanwomeng.github.io/post/%E5%81%8F%E5%B7%AE%E4%B8%8E%E6%96%B9%E5%B7%AE/</link>
      <pubDate>Tue, 23 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gaoshanwomeng.github.io/post/%E5%81%8F%E5%B7%AE%E4%B8%8E%E6%96%B9%E5%B7%AE/</guid>
      <description>1.偏差bias bias描述的是根据样本拟合出的模型的输出预测结果的期望与样本真实结果的差距。 简单讲，就是在样本上拟合的好不好。要想在bias上表现好，low bias，就得复杂化模型，增加模型的参数，</description>
    </item>
    
    <item>
      <title>梯度下降算法</title>
      <link>https://gaoshanwomeng.github.io/post/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95%E7%AE%80%E4%BB%8B/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gaoshanwomeng.github.io/post/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95%E7%AE%80%E4%BB%8B/</guid>
      <description>梯度下降（gradient descent）在机器学习中应用十分的广泛，不论是在线性回归还是Logistic回归中，它的主要目的是通过迭代找到目标函数的最小值，或者收敛到最小值。 1.算法思想 梯度下降法的</description>
    </item>
    
  </channel>
</rss>
